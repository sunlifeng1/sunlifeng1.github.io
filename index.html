<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>孙利峰</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="孙利峰">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="孙利峰">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="孙利峰">
<meta name="twitter:description">
  
    <link rel="alternate" href="/atom.xml" title="孙利峰" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">孙利峰</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-搞定iOS与js交互" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/02/15/搞定iOS与js交互/" class="article-date">
  <time datetime="2016-02-15T14:38:11.000Z" itemprop="datePublished">2016-02-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/02/15/搞定iOS与js交互/">搞定iOS与js交互</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>先看这篇文章： <a href="http://www.open-open.com/lib/view/open1419305655562.html" target="_blank" rel="external">http://www.open-open.com/lib/view/open1419305655562.html</a><br><a href="http://blog.csdn.net/lizhongfu2013/article/details/9232129" target="_blank" rel="external">http://blog.csdn.net/lizhongfu2013/article/details/9232129</a><br><a href="http://blog.csdn.net/lizhongfu2013/article/details/9236357" target="_blank" rel="external">http://blog.csdn.net/lizhongfu2013/article/details/9236357</a><br>干货好文章 <a href="http://www.jianshu.com/p/a329cd4a67ee" target="_blank" rel="external">http://www.jianshu.com/p/a329cd4a67ee</a><br>干货好文章 <a href="http://ios.jobbole.com/84491/" target="_blank" rel="external">http://ios.jobbole.com/84491/</a><br>交互范例 ：<a href="http://www.open-open.com/lib/view/open1463553967635.html" target="_blank" rel="external">http://www.open-open.com/lib/view/open1463553967635.html</a><br><a href="http://www.open-open.com/lib/view/open1456311816823.html" target="_blank" rel="external">http://www.open-open.com/lib/view/open1456311816823.html</a></p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/02/15/搞定iOS与js交互/" data-id="cipjh2n8q000mdhs6xe1y5ux6" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-移动直播开发技术介绍" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/01/28/移动直播开发技术介绍/" class="article-date">
  <time datetime="2016-01-28T14:29:41.000Z" itemprop="datePublished">2016-01-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/28/移动直播开发技术介绍/">移动直播开发技术介绍</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>现今移动直播技术上的挑战要远远难于传统设备或电脑直播，其完整的处理环节包括但不限于：音视频采集、美颜/滤镜/特效处理、编码、封包、推流、转码、分发、解码/渲染/播放等。</p>
<p>直播常见的问题包括</p>
<p>主播在不稳定的网络环境下如何稳定推流？<br>偏远地区的观众如何高清流畅观看直播？<br>直播卡顿时如何智能切换线路？<br>如何精确度量直播质量指标并实时调整？<br>移动设备上不同的芯片平台如何高性能编码和渲染视频？<br>美颜等滤镜特效处理怎么做？<br>如何实现播放秒开？<br>如何保障直播持续播放流畅不卡顿？</p>
<p>本次分享将为大家揭开移动直播核心技术的神秘面纱。</p>
<p>视频、直播等基础知识</p>
<p>什么是视频？</p>
<p>首先我们需要理解一个最基本的概念：视频。从感性的角度来看，视频就是一部充满趣味的影片，可以是电影，可以是短片，是一连贯的视觉冲击力表现丰富的画面和音频。但从理性的角度来看，视频是一种有结构的数据，用工程的语言解释，我们可以把视频剖析成如下结构：</p>
<p>内容元素 ( Content )<br>图像 ( Image )<br>音频 ( Audio )<br>元信息 ( Metadata ) </p>
<p>编码格式 ( Codec )<br>Video : H.264，H.265, …<br>Audio : AAC， HE-AAC, …</p>
<p>容器封装 (Container)<br>MP4，MOV，FLV，RM，RMVB，AVI，…</p>
<p>任何一个视频 Video 文件，从结构上讲，都是这样一种组成方式：</p>
<p>由图像和音频构成最基本的内容元素；<br>图像经过视频编码压缩格式处理（通常是 H.264）；<br>音频经过音频编码压缩格式处理（例如 AAC）；<br>注明相应的元信息（Metadata）；</p>
<p>最后经过一遍容器（Container）封装打包（例如 MP4），构成一个完整的视频文件。</p>
<p>如果觉得难以理解，可以想象成一瓶番茄酱。最外层的瓶子好比这个容器封装（Container），瓶子上注明的原材料和加工厂地等信息好比元信息（Metadata），瓶盖打开（解封装）后，番茄酱本身好比经过压缩处理过后的编码内容，番茄和调料加工成番茄酱的过程就好比编码（Codec），而原材料番茄和调料则好比最原本的内容元素（Content）。</p>
<p>视频的实时传输</p>
<p>简而言之，理性的认知视频的结构后，有助于我们理解视频直播。如果视频是一种“有结构的数据”，那么视频直播无疑是实时传输这种“有结构的数据”（视频）的方式。</p>
<p>那么一个显而易见的问题是：如何实时（Real-Time）传输这种“有结构的数据”（视频）呢？</p>
<p>这里边一个悖论是：一个经过容器（Container）封装后的视频，一定是不可变的 ( Immutable ) 视频文件，不可变的 ( Immutable ) 的视频文件已经是一个生产结果，根据“相对论”，而这个生产结果显然不可能精确到实时的程度，它已经是一段时空的记忆。</p>
<p>因此视频直播，一定是一个 “边生产，边传输，边消费”的过程。这意味着，我们需要更近一步了解视频从原始的内容元素 ( 图像和音频 ) 到成品 ( 视频文件 ) 之前的中间过程 ( 编码 )。</p>
<p>视频编码压缩</p>
<p>不妨让我们来深入浅出理解视频编码压缩技术。</p>
<p>为了便于视频内容的存储和传输，通常需要减少视频内容的体积，也就是需要将原始的内容元素(图像和音频)经过压缩，压缩算法也简称编码格式。例如视频里边的原始图像数据会采用 H.264 编码格式进行压缩，音频采样数据会采用 AAC 编码格式进行压缩。</p>
<p>视频内容经过编码压缩后，确实有利于存储和传输; 不过当要观看播放时，相应地也需要解码过程。因此编码和解码之间，显然需要约定一种编码器和解码器都可以理解的约定。就视频图像编码和解码而言，这种约定很简单：</p>
<p>编码器将多张图像进行编码后生产成一段一段的 GOP ( Group of Pictures ) ， 解码器在播放时则是读取一段一段的 GOP 进行解码后读取画面再渲染显示。</p>
<p>GOP ( Group of Pictures ) 是一组连续的画面，由一张 I 帧和数张 B / P 帧组成，是视频图像编码器和解码器存取的基本单位，它的排列顺序将会一直重复到影像结束。</p>
<p>I 帧是内部编码帧（也称为关键帧），P 帧是前向预测帧（前向参考帧），B 帧是双向内插帧（双向参考帧）。简单地讲，I 帧是一个完整的画面，而 P 帧和 B 帧记录的是相对于 I 帧的变化。</p>
<p>如果没有 I 帧，P 帧和 B 帧就无法解码。</p>
<p>小结一下，一个视频 ( Video ) ，其图像部分的数据是一组 GOP 的集合, 而单个 GOP 则是一组 I / P / B 帧图像的集合。</p>
<p>在这样的一种几何关系中，Video 好比一个 “物体”，GOP 好比 “分子”，I / P / B 帧的图像则好比 “原子”。</p>
<p>想象一下，如果我们把传输一个 “物体”，改成传输一个一个的 “原子”，将最小颗粒以光速传送，那么以人的生物肉眼来感知，将是一种怎样的体验？</p>
<p>什么是视频直播？</p>
<p>不难脑洞大开一下，直播就是这样的一种体验。视频直播技术，就是将视频内容的最小颗粒 ( I / P / B 帧，…)，基于时间序列，以光速进行传送的一种技术。</p>
<p>简而言之，直播就是将每一帧数据 ( Video / Audio / Data Frame )，打上时序标签 ( Timestamp ) 后进行流式传输的过程。发送端源源不断的采集音视频数据，经过编码、封包、推流，再经过中继分发网络进行扩散传播，播放端再源源不断地下载数据并按时序进行解码播放。如此就实现了 “边生产、边传输、边消费” 的直播过程。</p>
<p>理解以上两个关于 视频 和 直播 两个基础概念后，接下来我们就可以一窥直播的业务逻辑了。</p>
<p>直播的业务逻辑</p>
<p>如下是一个最精简的一对多直播业务模型，以及各个层级之间的协议。</p>
<p>各协议差异对比如下</p>
<p>以上就是关于直播技术的一些基础概念。下面我们进一步了解下影响人们视觉体验的直播性能指标。</p>
<p>影响视觉体验的直播性能指标</p>
<p>直播第一个性能指标是延迟，延迟是数据从信息源发送到目的地所需的时间。</p>
<p>根据爱因斯坦的狭义相对论，光速是所有能量、物质和信息运动所能达到的最高速度，这个结论给传播速度设定了上限。因此，即便我们肉眼感觉到的实时，实际上也是有一定的延迟。</p>
<p>由于 RTMP/HLS 是基于 TCP 之上的应用层协议，TCP 三次握手，四次挥手，慢启动过程中的每一次往返来回，都会加上一次往返耗时 ( RTT )，这些交互过程都会增加延迟。</p>
<p>其次根据 TCP 丢包重传特性，网络抖动可能导致丢包重传，也会间接导致延迟加大。</p>
<p>一个完整的直播过程，包括但不限于以下环节：采集、处理、编码、封包、推流、传输、转码、分发、拉流、解码、播放。从推流到播放，再经过中间转发环节，延迟越低，则用户体验越好。</p>
<p>第二个直播性能指标卡顿，是指视频播放过程中出现画面滞帧，让人们明显感觉到“卡”。单位时间内的播放卡顿次数统计称之为卡顿率。</p>
<p>造成卡顿的因素有可能是推流端发送数据中断，也有可能是公网传输拥塞或网络抖动异常，也有可能是终端设备的解码性能太差。卡顿频次越少或没有，则说明用户体验越好。</p>
<p>第三个直播性能指标首屏耗时，指第一次点击播放后，肉眼看到画面所等待的时间。技术上指播放器解码第一帧渲染显示画面所花的耗时。通常说的 “秒开”，指点击播放后，一秒内即可看到播放画面。首屏打开越快，说明用户体验越好。</p>
<p>如上三个直播性能指标，分别对应一个低延迟、高清流畅、极速秒开 的用户体验诉求。了解这三个性能指标，对优化移动直播 APP 的用户体验至关重要。</p>
<p>那么移动直播场景下具体而言有哪些常见的坑呢？</p>
<p>根据实践总结下来的经验，移动平台上视频直播的坑主要可以总结为两方面：设备差异，以及网络环境这些场景下带来的技术考验。</p>
<p>移动直播场景的坑与规避措施</p>
<p>不同芯片平台上的编码差异</p>
<p>iOS 平台上无论硬编还是软编，由于是 Apple 一家公司出厂，几乎不存在因为芯片平台不同而导致的编码差异。</p>
<p>然而，在 Android 平台上，Android Framework SDK 提供的 MediaCodec 编码器，在不同的芯片平台上，差异表现很大， 不同的厂家使用不同的芯片，而不同的芯片平台上 Android MediaCodec 表现略有差异，通常实现全平台兼容的成本不低。</p>
<p>另外就是 Android MediaCodec 硬编层面的 H.264 编码画质参数是固定的 baseline，所以画质通常也一般。因此，在 Android 平台下，推荐是用软编，好处是画质可调控，兼容性也更好。</p>
<p>低端设备如何上高性能地采集和编码？</p>
<p>例如 Camera 采集输出的可能是图片，一张图的体积并不会小，如果采集的频次很高，编码的帧率很高，每张图都经过编码器，那么编码器又可能会出现过载。</p>
<p>这个时候，可以考虑在编码前，不影响画质的前提下（前面我们讲过帧率的微观意义），进行选择性丢帧，以此降低编码环节的功耗开销。</p>
<p>弱网下如何保障高清流畅推流</p>
<p>移动网络下，通常容易遇到网络不稳定，连接被重置，断线重连，一方面频繁重连，建立连接需要开销。另一方面尤其是发生 GPRS / 2G / 3G / 4G 切换时，带宽可能出现瓶颈。当带宽不够，帧率较高/码率较高的内容较难发送出去，这个时候就需要可变码率支持。</p>
<p>即在推流端，可检测网络状态和简单测速，动态来切换码率，以保障网络切换时的推流流畅。</p>
<p>其次编码、封包、推流 这一部分的逻辑也可以做微调，可以尝试选择性丢帧，比如优先丢视频参考帧（不丢 I 帧和音频帧 )，这样也可以减少要传输的数据内容，但同时又达到了不影响画质和版视听流畅的目的。</p>
<p>需要区分直播流的状态和业务状态</p>
<p>直播是媒体流、APP 的交互是 API 信令流，两者的状态不能混为一谈。尤其是不能基于 APP 的交互的 API 状态来判断直播流的状态。</p>
<p>以上是移动直播场景下常见的几个坑和规避措施。</p>
<p>移动直播场景其他优化措施</p>
<p>一、怎么优化打开速度，达到传说中的 “秒开”？</p>
<p>大家可能会看到，市面上某些手机直播 APP 的打开速度非常快，一点就开。而某些手机直播 APP，点击播放后要等好几秒以后才能播放。是什么原因导致如此的天壤之别呢？</p>
<p>大部分播放器都是拿到一个完成的 GOP 后才能解码播放，基于 FFmpeg 移植的播放器甚至需要等待音画时间戳同步后才能播放（如果一个直播里边没有音频只有视频相当于要等待音频超时后才能播放画面）。</p>
<p>“秒开”可以从以下几个方面考虑：</p>
<ol>
<li>改写播放器逻辑让播放器拿到第一个关键帧后就给予显示。</li>
</ol>
<p>GOP 的第一帧通常都是关键帧，由于加载的数据较少，可以达到 “首帧秒开”。</p>
<p>如果直播服务器支持 GOP 缓存，意味着播放器在和服务器建立连接后可立即拿到数据，从而省却跨地域和跨运营商的回源传输时间。</p>
<p>GOP 体现了关键帧的周期，也就是两个关键帧之间的距离，即一个帧组的最大帧数。假设一个视频的恒定帧率是 24fps（即1秒24帧图像），关键帧周期为 2s，那么一个 GOP 就是 48 张图像。一般而言，每一秒视频至少需要使用一个关键帧。</p>
<p>增加关键帧个数可改善画质（GOP 通常为 FPS 的倍数），但是同时增加了带宽和网络负载。这意味着，客户端播放器下载一个 GOP，毕竟该 GOP 存在一定的数据体积，如果播放端网络不佳，有可能不是能够快速在秒级以内下载完该 GOP，进而影响观感体验。</p>
<p>如果不能更改播放器行为逻辑为首帧秒开，直播服务器也可以做一些取巧处理，比如从缓存 GOP 改成缓存双关键帧（减少图像数量），这样可以极大程度地减少播放器加载 GOP 要传输的内容体积。</p>
<ol>
<li>在 APP 业务逻辑层面方面优化。</li>
</ol>
<p>比如提前做好 DNS 解析（省却几十毫秒），和提前做好测速选线（择取最优线路）。经过这样的预处理后，在点击播放按钮时，将极大提高下载性能。</p>
<p>一方面，可以围绕传输层面做性能优化；另一方面，可以围绕客户播放行为做业务逻辑优化。两者可以有效的互为补充，作为秒开的优化空间。</p>
<p>二、美颜等滤镜如何处理？</p>
<p>在手机直播场景下，这就是一个刚需。没有美颜功能的手机直播 APP，主播基本不爱用。可以在采集画面后，将数据送给编码器之前，将数据源回调给滤镜处理程序，原始数据经过滤镜处理完后，再送回给编码器进行编码即可。</p>
<p>除了移动端可以做体验优化之外，直播流媒体服务端架构也可以降低延迟。例如收流服务器主动推送 GOP 至边缘节点，边缘节点缓存 GOP，播放端则可以快速加载，减少回源延迟。</p>
<p>其次，可以贴近终端就近处理和分发</p>
<p>三、如何保障直播持续播放流畅不卡顿？</p>
<p>“秒开”解决的是直播首次加载的播放体验，如何保障直播持续播放过程中的画面和声音视听流畅呢？因为，一个直播毕竟不是一个 HTTP 一样的一次性请求，而是一个 Socket 层面的长连接维持，直到直到主播主动终止推流。</p>
<p>上述我们讲过卡顿的定义：即播放时画面滞帧，触发了人们的视觉感受。在不考虑终端设备性能差异的情况下，针对网络传输层面的原因，我们看看如何保障一个持续的直播不卡顿。</p>
<p>这其实是一个直播过程中传输网络不可靠时的容错问题。例如，播放端临时断网了，但又快速恢复了，针对这种场景，播放端如果不做容错处理，很难不出现黑屏或是重新加载播放的现象。</p>
<p>为了容忍这种网络错误，并达到让终端用户无感知，客户端播放器可以考虑构建一个FIFO（先进先出）的缓冲队列，解码器从播放缓存队列读取数据，缓存队列从直播服务器源源不断的下载数据。通常，缓存队列的容量是以时间为单位（比如3s），在播放端网络不可靠时，客户端缓存区可以起到“断网无感”的过渡作用。</p>
<p>显然，这只是一个“缓兵之计”，如果直播服务器边缘节点出现故障，而此时客户端播放器又是长连接，在无法收到对端的连接断开信号，客户端的缓冲区容量再大也不管用了，这个时候就需要结合客户端业务逻辑来做调度。</p>
<p>重要的是客户端结合服务端，可以做精准调度。在初始化直播推流之前，例如基于 IP 地理位置和运营商的精确调度，分配线路质量最优的边缘接入节点。在直播推流的过程中，可以实时监测帧率反馈等质量数据，基于直播流的质量动态调整线路。</p>
<p>Q &amp; A</p>
<ol>
<li><p>关键帧设置频率一般是多少？有没有根据接入动态设置？过长首屏秒会很难做到。<br>徐立：关键帧间隔越长，也就是 GOP 越长，理论上画面越高清。但是生成 HLS 直播时，最小切割粒度也是一个 GOP，所以针对交互直播，通常不建议 GOP 设置太长。直播一般 2 个关键帧间隔即可。比如帧率是 24fps， 那么 2 个关键帧的间隔就是 48fps ，这个 GOP 就是2s。</p>
</li>
<li><p>七牛这个直播是用的网宿加速？有遇到什么坑没？<br>徐立：七牛在直播方面主要是自建节点，也支持融合众多第三方 CDN 服务商，多样化的线路组合为客户提供更优质的服务。在和第三方 CDN 合作的过程中遇到的问题等有机会再做更细粒度的交流和分享。</p>
</li>
<li><p>RTMP 直播流除了优化线路外，还有什么加速手段吗？<br>徐立：物理上优化线路，逻辑上优化策略，比如选择性丢帧，不影响编码画质的前提下减轻传输体积。</p>
</li>
<li><p>OBS 推流，播放端 HLS 出现视/音频不同步是哪个环节的问题？怎么优化？<br>徐立：有可能是采集端的问题，如果是采集端编码环节就出现音画不同步，可以在收流服务器上做音画时间戳同步，这样是全局的校对。如果是播放端解码性能问题，那么需要调节播放逻辑，比如保证音画时间戳强一致性的前提下，选择性丢一部帧。</p>
</li>
<li><p>PPT 前几页中一个概念好像错了，I 帧不是关键帧，IDR 帧才是。IDR 帧是 I 帧，但是 I 帧不一定是 IDR 帧。只有 IDR 帧才是可重入的。<br>徐立：中文都把 I 帧翻译成关键帧了，不过既然提到了 IDR 帧，可以展开说明一下。所有的 IDR 帧都是 I 帧，但是并不是所有 I 帧都是 IDR 帧，IDR 帧是 I 帧的子集。I 帧严格定义是帧内编码帧，由于是一个全帧压缩编码帧，通常用 I 帧表示 “关键帧”。IDR 是基于 I 帧的一个 “扩展”，带了控制逻辑，IDR 图像都是 I 帧图像，当解码器解码到 IDR 图像时，会立即将参考帧队列清空，将已解码的数据全部输出或抛弃。重新查找参数集，开始一个新的序列。这样如果前一个序列出现重大错误，在这里可以获得重新同步的机会。IDR 图像之后的图像永远不会使用 IDR 之前的图像的数据来解码。</p>
</li>
<li><p>有没有调研过 nginx rtmp module，为什么没有用，对它有什么评价？<br>徐立：有调研过，nginx_rtmp_module 是单进程多线程，非 go 这种轻量级线程/协程用并发自然语义的方式编写流业务。nginx 原本的代码量较大（约 16 万行，但和直播业务相关的功能并不是很多）。且主要靠写 nginx.conf 做配置租户，通常单租户可以，但业务可扩展性方面不是很灵活，可满足基本需求，不满足高级功能。</p>
</li>
<li><p>用到了那些开源软件？编码用的是 x264 吗？直播服务器你们自己开发还是开源的？<br>徐立：直播服务器用 go 开发的，移动端编码优先硬编，软编用 x264</p>
</li>
<li><p>请教一下用 OBS 推流到 nginx_rtmp_module 的时候是已经做了视频压缩了还是需要基于 OBS 再开发？<br>徐立：OBS 把编码压缩都做了，不需要再开发。</p>
</li>
<li><p>视频直播想在 HLS 流中无缝插入一段广告的 ts 文件，有问题想请教一下：1、这段 ts 的分辨率是否一定要和之前的视频流一致？2、pts 时间戳是否要和上一个 ts 递增？<br>徐立：1、可以不一致。这种情况两段视频完全是独立状态，可以没有任何关系，只需要插入 discontinue 标记，播放器在识别到这个标记之后重置解码器参数就可以无缝播放，画面会很平滑的切换。2、不需要递增。举个例子，视频 A 正在直播，播放到 pts 在 5s 的时候，插入一个视频 B，需要先插入一个 discontinue，再插入 B，等 B 播放完之后，再插入一个 discontinue，再插入 A，这个时候 A 的 pts 可以和之前递增，也可以按照中间插入的 B 的时长做偏移，一般做点播和时移的时候 pts 会连续递增，直播的话会算上 B 的时长。</p>
</li>
</ol>
<p>PPT 下载地址</p>
<p><a href="http://77fycs.com2.z0.glb.qiniucdn.com/pili_technology_sharing.pdf" target="_blank" rel="external">http://77fycs.com2.z0.glb.qiniucdn.com/pili_technology_sharing.pdf</a></p>
<p>由于移动直播在实践上还有非常多细节，本文未能全部覆盖，感兴趣的朋友欢迎在文章最后留言讨论。</p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/01/28/移动直播开发技术介绍/" data-id="cipjh2n9g000pdhs6z4kr07il" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Bilibili开源的直播框架" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/01/22/Bilibili开源的直播框架/" class="article-date">
  <time datetime="2016-01-22T14:20:09.000Z" itemprop="datePublished">2016-01-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/22/Bilibili开源的直播框架/">Bilibili开源的直播框架</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>文档地址：<a href="http://www.jianshu.com/p/1f06b27b3ac0" target="_blank" rel="external">http://www.jianshu.com/p/1f06b27b3ac0</a></p>
<p>ijkplayer 是一款做视频直播的框架, 基于ffmpeg, 支持 Android 和 iOS, 网上也有很多集成说明, 但是个人觉得还是不够详细, 在这里详细的讲一下在 iOS 中如何集成ijkplayer, 即便以前从没有接触过, 按着下面做也可以集成成功!</p>
<p>一. 下载ijkplayer<br>ijkplayer下载地址:<a href="https://github.com/Bilibili/ijkplayer" target="_blank" rel="external">https://github.com/Bilibili/ijkplayer</a><br>下载完成后解压</p>
<p>二. 编译 ijkplayer<br>说是编译 ijkplayer, 其实是编译 ffmpeg, 在这里我们已经下载好了ijkplayer, 所以 github 上README.md中的Build iOS那一步中有一些步骤是不需要的.<br>下面开始一步一步编译:<br>1.打开终端, cd 到jkplayer-master文件夹中, 也就是下载完解压后的文件夹</p>
<p>2.执行命令行./init-ios.sh, 这一步是去下载 ffmpeg 的, 时间会久一点, 耐心等一下</p>
<p>3.在第2步中下载完成后, 执行cd ios, 也就是进入到 ios目录中</p>
<p>4.进入 ios 文件夹后, 在终端依次执行./compile-ffmpeg.sh clean和./compile-ffmpeg.sh all命令, 编译 ffmpeg, 也就是README.md中这两步</p>
<p>编译 ffmpeg<br>编译时间较久, 耐心等待一下.</p>
<p>三. 打包IJKMediaFramework.framework框架<br>集成 ijkplayer 有两种方法:<br>一种方法是按照IJKMediaDemo工程中那样, 直接导入工程IJKMediaPlayer.xcodeproj, 在这里不做介绍</p>
<p>导入IJKMediaPlayer.xcodeproj<br>第二种集成方法是把 ijkplayer 打包成framework导入工程中使用. 下面开始介绍如何打包IJKMediaFramework.framework, 按下面步骤开始一步一步做:</p>
<p>首先打开工程IJKMediaPlayer.xcodeproj<br>要打包的 framework 工程.png<br>2.工程打开后设置工程的 scheme</p>
<p>3.设置好 scheme 后, 分别选择真机和模拟器进行编译, 编译完成后, 进入 Finder</p>
<p>进入 Finder 后, 可以看到有真机和模拟器两个版本的编译结果</p>
<p>运行后生成的文件.png<br>下面开始合并真机和模拟器版本的 framework, 注意不要合并错了, 合并的是这个文件</p>
<p>合并真机和模拟器文件中的这个文件.png<br>打开终端, 进行合并, 命令行具体格式为:</p>
<p>lipo -create “真机版本路径” “模拟器版本路径” -output “合并后的文件路径”<br>合并</p>
<p>合并生成后的文件.png<br>下面很重要, 需要用合并后的IJKMediaFramework把原来的IJKMediaFramework替换掉, 如下图, 希望你能看懂:</p>
<p>用合并生成的文件替换原来的文件.png<br>上图中的1、2两步完成后, 绿色框住的那个IJKMediaFramework.framework文件就是我们需要的框架了, 可以复制出来, 稍后我们需要导入工程使用.</p>
<p>四. iOS工程中集成ijkplayer<br>新建工程, 导入合并后的IJKMediaFramework.framework以及相关依赖框架以及相关依赖框架</p>
<p>导入 framework及依赖框架.png<br>导入框架后, 在ViewController.m进行测试, 首先导入IJKMediaFramework.h头文件, 编译看有没有错, 如果没有错说明集成成功.<br>接着开始在ViewController.m文件中使用IJKMediaFramework框架进行测试使用, 写一个简单的直播视频进行测试, 在这里看一下运行后的结果, 后面会放上 Demo 供下载.</p>
<p>文／jianshu_wl（简书作者）<br>原文链接：<a href="http://www.jianshu.com/p/1f06b27b3ac0" target="_blank" rel="external">http://www.jianshu.com/p/1f06b27b3ac0</a><br>著作权归作者所有，转载请联系作者获得授权，并标注“简书作者”。</p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/01/22/Bilibili开源的直播框架/" data-id="cipjh2n720001dhs6qced6kf1" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS三种视屏录制方式" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/01/14/iOS三种视屏录制方式/" class="article-date">
  <time datetime="2016-01-14T14:14:49.000Z" itemprop="datePublished">2016-01-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2016/01/14/iOS三种视屏录制方式/">iOS三种视屏录制方式</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>随着每一代 iPhone 处理能力和相机硬件配置的提高，使用它来捕获视频也变得更加有意思。它们小巧，轻便，低调，而且与专业摄像机之间的差距已经变得非常小，小到在某些情况下，iPhone 可以真正替代它们。</p>
<p>这篇文章讨论了关于如何配置视频捕获管线 (pipeline) 和最大限度地利用硬件性能的一些不同选择。 这里有个使用了不同管线的样例 app，可以在 GitHub 查看。</p>
<p>UIImagePickerController</p>
<p>目前，将视频捕获集成到你的应用中的最简单的方法是使用 UIImagePickerController。这是一个封装了完整视频捕获管线和相机 UI 的 view controller。</p>
<p>在实例化相机之前，首先要检查设备是否支持相机录制：</p>
<p>Objective-C</p>
<p>if ([UIImagePickerController<br>isSourceTypeAvailable:UIImagePickerControllerSourceTypeCamera]) {<br>NSArray <em>availableMediaTypes = [UIImagePickerController<br>availableMediaTypesForSourceType:UIImagePickerControllerSourceTypeCamera];<br>if ([availableMediaTypes containsObject:(NSString </em>)kUTTypeMovie]) {<br>// 支持视频录制<br>}<br>}<br>然后创建一个 UIImagePickerController 对象，设置好代理便于进一步处理录制好的视频 (比如存到相册) 以及对于用户关闭相机作出响应：</p>
<p>Objective-C</p>
<p>UIImagePickerController <em>camera = [UIImagePickerController new];<br>camera.sourceType = UIImagePickerControllerSourceTypeCamera;<br>camera.mediaTypes = @[(NSString </em>)kUTTypeMovie];<br>camera.delegate = self;<br>这是你实现一个功能完善的摄像机所需要写的所有代码。</p>
<p>相机配置</p>
<p>UIImagePickerController 提供了额外的配置选项。</p>
<p>通过设置 cameraDevice 属性可以选择一个特定的相机。这是一个 UIImagePickerControllerCameraDevice 枚举，默认情况下是 UIImagePickerControllerCameraDeviceRear，你也可以把它设置为 UIImagePickerControllerCameraDeviceFront。每次都应事先确认你想要设置的相机是可用的：</p>
<p>Objective-C</p>
<p>UIImagePickerController *camera = …<br>if ([UIImagePickerController isCameraDeviceAvailable:UIImagePickerControllerCameraDeviceFront]) {<br>[camera setCameraDevice:UIImagePickerControllerCameraDeviceFront];<br>}<br>videoQuality 属性用于控制录制视频的质量。它允许你设置一个特定的编码预设，从而改变视频的比特率和分辨率。以下是六种预设：</p>
<p>Objective-C</p>
<p>enum {<br>UIImagePickerControllerQualityTypeHigh             = 0,<br>UIImagePickerControllerQualityTypeMedium           = 1,  // default  value<br>UIImagePickerControllerQualityTypeLow              = 2,<br>UIImagePickerControllerQualityType640x480          = 3,<br>UIImagePickerControllerQualityTypeIFrame1280x720   = 4,<br>UIImagePickerControllerQualityTypeIFrame960x540    = 5<br>};<br>typedef NSUInteger  UIImagePickerControllerQualityType;<br>前三种为相对预设 (low, medium, high)。这些预设的编码配置会因设备不同而不同。如果选择 high，那么你选定的相机会提供给你该设备所能支持的最高画质。后面三种是特定分辨率的预设 (640×480 VGA, 960×540 iFrame, 和 1280×720 iFrame)。</p>
<p>自定义 UI</p>
<p>就像上面提到的，UIImagePickerController 自带一套相机 UI，可以直接使用。然而，你也可以自定义相机的控件，通过隐藏默认控件，然后创建带有控件的自定义视图，并覆盖在相机预览图层上面：</p>
<p>Objective-C</p>
<p>UIView *cameraOverlay = …<br>picker.showsCameraControls = NO;<br>picker.cameraOverlayView = cameraOverlay;<br>然后你需要将你覆盖层上的控件关联上 UIImagePickerController 的控制方法 (比如，startVideoCapture 和 stopVideoCapture)。</p>
<p>AVFoundation</p>
<p>如果你想要更多关于处理捕获视频的方法，而这些方法是 UIImagePickerController 所不能提供的，那么你需要使用 AVFoundation。</p>
<p>AVFoundation 中关于视频捕获的主要的类是 AVCaptureSession。它负责调配影音输入与输出之间的数据流：</p>
<p>AVCaptureSession setup<br>使用一个 capture session，你需要先实例化，添加输入与输出，接着启动从输入到输出之间的数据流：</p>
<p>Objective-C</p>
<p>AVCaptureSession <em>captureSession = [AVCaptureSession new];<br>AVCaptureDeviceInput </em>cameraDeviceInput = …<br>AVCaptureDeviceInput <em>micDeviceInput = …<br>AVCaptureMovieFileOutput </em>movieFileOutput = … </p>
<p>if ([captureSession canAddInput:cameraDeviceInput]) { </p>
<p>[captureSession addInput:cameraDeviceInput];</p>
<p>}</p>
<p>if ([captureSession canAddInput:micDeviceInput]) { </p>
<p>[captureSession addInput:micDeviceInput];</p>
<p>}</p>
<p>if ([captureSession canAddOutput:movieFileOutput]) { </p>
<p>[captureSession addOutput:movieFileOutput];</p>
<p>}</p>
<p>[captureSession startRunning];<br>(为了简单起见，调度队列 (dispatch queue) 的相关代码已经从上面那段代码中省略了。所有对 capture session 的调用都是阻塞的，因此建议将它们分配到后台串行队列中。)</p>
<p>capture session 可以通过一个 sessionPreset</p>
<p>来进一步配置，这可以用来指定输出质量的等级。有 11 种不同的预设模式：</p>
<p>Objective-C</p>
<p>NSString <em>const  AVCaptureSessionPresetPhoto;<br>NSString </em>const  AVCaptureSessionPresetHigh;<br>NSString <em>const  AVCaptureSessionPresetMedium;<br>NSString </em>const  AVCaptureSessionPresetLow;<br>NSString <em>const  AVCaptureSessionPreset352x288;<br>NSString </em>const  AVCaptureSessionPreset640x480;<br>NSString <em>const  AVCaptureSessionPreset1280x720;<br>NSString </em>const  AVCaptureSessionPreset1920x1080;<br>NSString <em>const  AVCaptureSessionPresetiFrame960x540;<br>NSString </em>const  AVCaptureSessionPresetiFrame1280x720;<br>NSString *const  AVCaptureSessionPresetInputPriority;<br>第一个代表高像素图片输出。 接下来的九个和之前我们在设置 UIImagePickerController 的 videoQuality 时看到过的 UIImagePickerControllerQualityType 选项非常相似，不同的是，这里有一些额外可用于 capture session 的预设。 最后一个 (AVCaptureSessionPresetInputPriority) 代表 capture session 不去控制音频与视频输出设置。而是通过已连接的捕获设备的 activeFormat 来反过来控制 capture session 的输出质量等级。在下一节，我们将会看到更多关于设备和设备格式的细节。</p>
<p>输入<br>AVCaptureSession 的输入其实就是一个或多个的 AVCaptureDevice 对象，这些对象通过 AVCaptureDeviceInput 连接上 capture session。</p>
<p>我们可以使用 [AVCaptureDevice devices] 来寻找可用的捕获设备。以 iPhone 6 为例：</p>
<p>Objective-C</p>
<p>(</p>
<p>“<avcapturefigvideodevice: 0x136514db0="" [back="" camera][com.apple.avfoundation.avcapturedevice.built-in_video:0]="">”,</avcapturefigvideodevice:></p>
<p>“<avcapturefigvideodevice: 0x13660be80="" [front="" camera][com.apple.avfoundation.avcapturedevice.built-in_video:1]="">”,</avcapturefigvideodevice:></p>
<p>“<avcapturefigaudiodevice: 0x174265e80="" [iphone="" microphone][com.apple.avfoundation.avcapturedevice.built-in_audio:0]="">”</avcapturefigaudiodevice:></p>
<p>)<br>视频输入<br>配置相机输入，需要实例化一个 AVCaptureDeviceInput 对象，参数是你期望的相机设备，然后把它添加到 capture session：</p>
<p>Objective-C</p>
<p>AVCaptureSession <em>captureSession = …<br>AVCaptureDevice </em>cameraDevice = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];<br>NSError *error; </p>
<p>AVCaptureDeviceInput *cameraDeviceInput = [[AVCaptureDeviceInput alloc] initWithDevice:cameraDevice error:&amp;error]; </p>
<p>if ([captureSession canAddInput:input]) {<br>[captureSession addInput:cameraDeviceInput];<br>}<br>如果上面提到的 capture session 预设列表里能满足你的需求，那你就不需要做更多的事情了。如果不够，比如你想要高的帧率，你将需要配置具体的设备格式。一个视频捕获设备有许多设备格式，每个都带有特定的属性和功能。下面是对于 iPhone6 的后置摄像头的一些例子 (一共有 22 种可用格式)：</p>
<p>Objective-C</p>
<p>格式     分辨率        FPS      HRSI       FOV   VIS   最大放大比例  Upscales    AF  ISO SS  HDR</p>
<p>420v    1280x720    5 - 240 1280x720    54.626  YES 49.12   1.09    1   29.0 - 928  0.000003-0.200000   NO</p>
<p>420f    1280x720    5 - 240 1280x720    54.626  YES 49.12   1.09    1   29.0 - 928  0.000003-0.200000   NO</p>
<p>420v    1920x1080   2 - 30  3264x1836   58.040  YES 95.62   1.55    2   29.0 - 464  0.000013-0.500000   YES</p>
<p>420f    1920x1080   2 - 30  3264x1836   58.040  YES 95.62   1.55    2   29.0 - 464  0.000013-0.500000   YES</p>
<p>420v    1920x1080   2 - 60  3264x1836   58.040  YES 95.62   1.55    2   29.0 - 464  0.000008-0.500000   YES</p>
<p>420f    1920x1080   2 - 60  3264x1836   58.040  YES 95.62   1.55    2   29.0 - 464  0.000008-0.500000   YES</p>
<p>格式 = 像素格式<br>FPS = 支持帧数范围<br>HRSI = 高像素静态图片尺寸<br>FOV = 视角<br>VIS = 该格式支持视频防抖<br>Upscales = 加入数字 upscaling 时的放大比例<br>AF = 自动对焦系统（1 是反差对焦，2 是相位对焦）<br>ISO = 支持感光度范围<br>SS = 支持曝光时间范围<br>HDR = 支持高动态范围图像<br>通过上面的那些格式，你会发现如果要录制 240 帧每秒的视频的话，可以根据想要的像素格式选用第一个或第二个格式。另外若是要捕获 1920×1080 的分辨率的视频的话，是不支持 240 帧每秒的。</p>
<p>配置一个具体设备格式，你首先需要调用 lockForConfiguration: 来获取设备的配置属性的独占访问权限。接着你简单地使用 setActiveFormat: 来设置设备的捕获格式。这将会自动把 capture session 的预设设置为 AVCaptureSessionPresetInputPriority。</p>
<p>一旦你设置了预想的设备格式，你就可以在这种设备格式的约束参数范围内进行进一步的配置了。</p>
<p>对于视频捕获的对焦，曝光和白平衡的设置，与图像捕获时一样，具体可参考第 21 期“iOS 上的相机捕捉”。除了那些，这里还有一些视频特有的配置选项。</p>
<p>你可以用捕获设备的 activeVideoMinFrameDuration 和 activeVideoMaxFrameDuration 属性设置帧速率，一帧的时长是帧速率的倒数。设置帧速率之前，要先确认它是否在设备格式所支持的范围内，然后锁住捕获设备来进行配置。为了确保帧速率恒定，可以将最小与最大的帧时长设置成一样的值：</p>
<p>Objective-C</p>
<p>NSError *error; </p>
<p>CMTime frameDuration = CMTimeMake(1, 60);<br>NSArray *supportedFrameRateRanges = [device.activeFormat videoSupportedFrameRateRanges];<br>BOOL frameRateSupported = NO; </p>
<p>for (AVFrameRateRange *range in supportedFrameRateRanges) {<br>if (CMTIME_COMPARE_INLINE(frameDuration, &gt;=, range.minFrameDuration) &amp;&amp;<br>CMTIME_COMPARE_INLINE(frameDuration, &lt;=, range.maxFrameDuration)) {<br>frameRateSupported = YES;<br>}<br>}</p>
<p>if (frameRateSupported &amp;&amp; [device lockForConfiguration:&amp;error]) {<br>[device setActiveVideoMaxFrameDuration:frameDuration];<br>[device setActiveVideoMinFrameDuration:frameDuration];<br>[device unlockForConfiguration];<br>}<br>视频防抖 是在 iOS 6 和 iPhone 4S 发布时引入的功能。到了 iPhone 6，增加了更强劲和流畅的防抖模式，被称为影院级的视频防抖动。相关的 API 也有所改动 (目前为止并没有在文档中反映出来，不过可以查看头文件）。防抖并不是在捕获设备上配置的，而是在 AVCaptureConnection 上设置。由于不是所有的设备格式都支持全部的防抖模式，所以在实际应用中应事先确认具体的防抖模式是否支持：</p>
<p>Objective-C</p>
<p>AVCaptureDevice *device = …; </p>
<p>AVCaptureConnection *connection = …;</p>
<p>AVCaptureVideoStabilizationMode stabilizationMode = AVCaptureVideoStabilizationModeCinematic; </p>
<p>if ([device.activeFormat isVideoStabilizationModeSupported:stabilizationMode]) { </p>
<p>[connection setPreferredVideoStabilizationMode:stabilizationMode];</p>
<p>}<br>iPhone 6 的另一个新特性就是视频 HDR (高动态范围图像)，它是“高动态范围的视频流，与传统的将不同曝光度的静态图像合成成一张高动态范围图像的方法完全不同”，它是内建在传感器中的。有两种方法可以配置视频 HDR：直接将 capture device 的 videoHDREnabled 设置为启用或禁用，或者使用 automaticallyAdjustsVideoHDREnabled 属性来留给系统处理。</p>
<p>技术参考：iPhone 6 和 iPhone Plus 的新 AV Foundation 相机特性</p>
<p>音频输入<br>之前展示的捕获设备列表里面只有一个音频设备，你可能觉得奇怪，毕竟 iPhone 6 有 3 个麦克风。然而因为有时会放在一起使用，便于优化性能，因此可能被当做一个设备来使用。例如在 iPhone 5 及以上的手机录制视频时，会同时使用前置和后置麦克风，用于定向降噪。</p>
<p>Technical Q&amp;A: AVAudioSession – Microphone Selection</p>
<p>大多数情况下，设置成默认的麦克风配置即可。后置麦克风会自动搭配后置摄像头使用 (前置麦克风则用于降噪)，前置麦克风和前置摄像头也是一样。</p>
<p>然而想要访问和配置单独的麦克风也是可行的。例如，当用户正在使用后置摄像头捕获场景的时候，使用前置麦克风来录制解说也应是可能的。这就要依赖于 AVAudioSession。 为了变更要访问的音频，audio session 首先需要设置为支持这样做的类别。然后我们需要遍历 audio session 的输入端口和端口数据来源，来找到我们想要的麦克风：</p>
<p>Objective-C</p>
<p>// 配置 audio session<br>AVAudioSession *audioSession = [AVAudioSession sharedInstance];<br>[audioSession setCategory:AVAudioSessionCategoryPlayAndRecord error:nil];<br>[audioSession setActive:YES error:nil];</p>
<p>// 寻找期望的输入端口<br>NSArray<em> inputs = [audioSession availableInputs];<br>AVAudioSessionPortDescription </em>builtInMic = nil; </p>
<p>for (AVAudioSessionPortDescription* port in inputs) {<br>if ([port.portType isEqualToString:AVAudioSessionPortBuiltInMic]) {<br>builtInMic = port;<br>break;<br>}<br>}</p>
<p>// 寻找期望的麦克风</p>
<p>for (AVAudioSessionDataSourceDescription* source in builtInMic.dataSources) { </p>
<p>if ([source.orientation isEqual:AVAudioSessionOrientationFront]) {<br>[builtInMic setPreferredDataSource:source error:nil];<br>[audioSession setPreferredInput:builtInMic error:&amp;error];<br>break;<br>}<br>}<br>除了设置非默认的麦克风配置，你也可以使用 AVAudioSession 来配置其他音频设置，比如音频增益和采样率等。</p>
<p>访问权限<br>有件事你需要记住，访问相机和麦克风需要先获得用户授权。当你给视频或音频创建第一个 AVCaptureDeviceInput 对象时，iOS 会自动弹出一次对话框，请求用户授权，但你最好还是自己实现下。之后你就可以在还没有被授权的时候，使用相同的代码来提示用户进行授权。当用户未授权时，对于录制视频或音频的尝试，得到的将是黑色画面和无声。</p>
<p>输出<br>输入配置完了，现在把我们的注意力转向 capture session 的输出。</p>
<p>AVCaptureMovieFileOutput</p>
<p>将视频写入文件，最简单的选择就是使用 AVCaptureMovieFileOutput 对象。把它作为输出添加到 capture session 中，就可以将视频和音频写入 QuickTime 文件，这只需很少的配置。</p>
<p>Objective-C</p>
<p>AVCaptureMovieFileOutput *movieFileOutput = [AVCaptureMovieFileOutput new]; </p>
<p>if([captureSession canAddOutput:movieFileOutput]){ </p>
<p>[captureSession addOutput:movieFileOutput];</p>
<p>}</p>
<p>// 开始录制</p>
<p>NSURL *outputURL = … </p>
<p>[movieFileOutput startRecordingToOutputFileURL:outputURL recordingDelegate:self];<br>当实际的录制开始或停止时，想要接收回调的话就必须要一个录制代理。当录制停止时，输出通常还在写入数据，等它完成之后会调用代理方法。</p>
<p>AVCaptureMovieFileOutput 有一些其他的配置选项，比如在某段时间后，在达到某个指定的文件尺寸时，或者当设备的最小磁盘剩余空间达到某个阈值时停止录制。如果你还需要更多设置，比如自定义视频音频的压缩率，或者你想要在写入文件之前，处理视频音频的样本，那么你需要一些更复杂的操作。</p>
<p>AVCaptureDataOutput 和 AVAssetWriter</p>
<p>如果你想要对影音输出有更多的操作，你可以使用 AVCaptureVideoDataOutput 和 AVCaptureAudioDataOutput 而不是我们上节讨论的 AVCaptureMovieFileOutput。</p>
<p>这些输出将会各自捕获视频和音频的样本缓存，接着发送到它们的代理。代理要么对采样缓冲进行处理 (比如给视频加滤镜)，要么保持原样传送。使用 AVAssetWriter 对象可以将样本缓存写入文件：</p>
<p>Using an AVAssetWriter</p>
<p>配置一个 asset writer 需要定义一个输出 URL 和文件格式，并添加一个或多个输入来接收采样的缓冲。我们还需要将输入的 expectsMediaInRealTime属性设置为 YES，因为它们需要从 capture session 实时获得数据。</p>
<p>Objective-C</p>
<p>NSURL *url = …; </p>
<p>AVAssetWriter *assetWriter = [AVAssetWriter assetWriterWithURL:url fileType:AVFileTypeMPEG4 error:nil]; </p>
<p>AVAssetWriterInput *videoInput = [[AVAssetWriterInput alloc] initWithMediaType:AVMediaTypeVideo outputSettings:nil]; </p>
<p>videoInput.expectsMediaDataInRealTime = YES; </p>
<p>AVAssetWriterInput *audioInput = [[AVAssetWriterInput alloc] initWithMediaType:AVMediaTypeAudio outputSettings:nil]; </p>
<p>audioInput.expectsMediaDataInRealTime = YES; </p>
<p>if ([assetWriter canAddInput:videoInput]) { </p>
<p>[assetWriter addInput:videoInput];</p>
<p>}</p>
<p>if ([assetWriter canAddInput:audioInput]) { </p>
<p>[assetWriter addInput:audioInput];</p>
<p>}<br>(这里推荐将 asset writer 派送到后台串行队列中调用。)</p>
<p>在上面的示例代码中，我们将 asset writer 的 outputSettings 设置为 nil。这就意味着附加上来的样本不会再被重新编码。如果你确实想要重新编码这些样本，那么需要提供一个包含具体输出参数的字典。关于音频输出设置的键值被定义在这里, 关于视频输出设置的键值定义在这里。</p>
<p>为了更简单点，AVCaptureVideoDataOutput 和 AVCaptureAudioDataOutput 分别带有 recommendedVideoSettingsForAssetWriterWithOutputFileType: 和 recommendedAudioSettingsForAssetWriterWithOutputFileType: 方法，可以生成与 asset writer 兼容的带有全部键值对的字典。所以你可以通过在这个字典里调整你想要重写的属性，来简单地定义你自己的输出设置。比如，增加视频比特率来提高视频质量等。</p>
<p>或者，你也可以使用 AVOutputSettingsAssistant 来配置输出设置的字典，但是从我的经验来看，使用上面的方法会更好，它们会提供更实用的输出设置，比如视频比特率。另外，AVOutputSettingsAssistant 似乎存在一些缺点，例如，当你改变希望的视频的帧速率时，视频的比特率并不会改变。</p>
<p>实时预览</p>
<p>当使用 AVFoundation 来做图像捕获时，我们必须提供一套自定义的用户界面。其中一个关键的相机交互组件是实时预览图。最简单的实现方式是通过把 AVCaptureVideoPreviewLayer 对象作为一个 sublayer 加到相机图层上去：</p>
<p>Objective-C</p>
<p>AVCaptureSession <em>captureSession = …;<br>AVCaptureVideoPreviewLayer </em>previewLayer = [AVCaptureVideoPreviewLayer layerWithSession:captureSession];<br>UIView *cameraView = …;<br>previewLayer.frame = cameraView.bounds;<br>[cameraView.layer addSublayer:previewLayer];<br>如果你想要更进一步操作，比如，在实时预览图加滤镜，你需要将 AVCaptureVideoDataOutput 对象加到 capture session，并且使用 OpenGL 展示画面，具体可查看该文“iOS 上的相机捕捉”</p>
<p>总结</p>
<p>有许多不同的方法可以给 iOS 上的视频捕获配置管线，从最直接的 UIImagePickerController，到精密配合的 AVCaptureSession 与 AVAssetWriter。如何抉择取决于你的项目要求，比如期望的视频质量和压缩率，或者是你想要展示给用户的相机控件。</p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/01/14/iOS三种视屏录制方式/" data-id="cipjh2n87000fdhs61x0lccnf" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS-通讯录写法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/11/23/iOS-通讯录写法/" class="article-date">
  <time datetime="2015-11-23T08:08:06.000Z" itemprop="datePublished">2015-11-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/11/23/iOS-通讯录写法/">iOS_通讯录写法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>苹果的通讯录功能在iOS7,iOS8,iOS9 都有着一定的不同，iOS7和8用的是 <addressbookui addressbookui.h=""> ，但是两个系统版本的代理方法有一些变化，有些代理方法都标注了 NS_DEPRECATED_IOS(2_0, 8_0) 并推荐了另一个代理方法与之对应。  而iOS8到iOS9则是直接弃用了<addressbookui addressbookui.h="">取而代之的是<contactsui contactsui.h="">，后者是OC调用，据说当时苹果宣布弃用AddressBookUI还引来了阵阵欢呼。这也就是在使用通讯录功能时得考虑版本各种判断，我也就是工作中遇到了这种坑，然后就顺手兼容封装了一下。希望能解决这个问题。</contactsui></addressbookui></addressbookui></p>
<p>我觉得通讯录这里的类结构没必要像SDWebImage或是Core Location这样列出来详细去说。大家用到通讯录无外乎就三个功能：</p>
<p>1.点击弹出通讯录页面，选择了一个联系人的电话后直接将信息填到页面输入框内。</p>
<p>2.遍历所有的通讯录数据统一做批量操作，搭建新页面或直接上传。</p>
<p>3.给通讯录写入一条信息。</p>
<p>这里会先对比一下iOS789的写法，最后奉上demo（一个封装后的库，提供了非常便利的api）。不关心内部实现的朋友可以直接拉到demo部分。</p>
<p>一、首先是获取通讯录的权限<br>iOS7和8保持一致</p>
<p><span style="font-size: 13px; font-family: 宋体;">    ABAuthorizationStatus status = ABAddressBookGetAuthorizationStatus();<br>ABAddressBookRef addressBookRef = ABAddressBookCreateWithOptions(NULL, NULL);<br>if (status == kABAuthorizationStatusNotDetermined) {<br>NSLog(@”还没问”);<br>ABAddressBookRequestAccessWithCompletion(addressBookRef, ^(bool granted, CFErrorRef error){<br>if(granted){<br>NSLog(@”点击同意”);<br>}else{<br>NSLog(@”点击拒绝”);<br>}<br>});<br>}else if (status == kABAuthorizationStatusAuthorized){<br>NSLog(@”已经授权”);<br>[self loadPerson];<br>}else {<br>NSLog(@”没有授权”);<br>// 弹窗提示去获取权限<br>}</span><br>iOS9及以后调用方法改成</p>
<p><span style="font-size: 13px; font-family: 宋体;">     CNAuthorizationStatus status = [CNContactStore authorizationStatusForEntityType:CNEntityTypeContacts];<br>if (status == CNAuthorizationStatusNotDetermined) {<br>[[[CNContactStore alloc]init] requestAccessForEntityType:CNEntityTypeContacts completionHandler:^(BOOL granted, NSError * _Nullable error) {<br>NSLog(@”还没问”);<br>if(granted){<br>NSLog(@”点击了同意”);<br>[self loadPerson];<br>}else{<br>NSLog(@”点击了拒绝”);<br>}<br>}];<br>}else if (status == CNAuthorizationStatusAuthorized){<br>NSLog(@已经授权”);<br>}else {<br>NSLog(@”没有授权”);<br>}    </span></p>
<p>二、弹出通讯录选择界面<br>iOS7的写法如下，代理方法的返回值大多是BOOL类型。</p>
<p><span style="font-size: 13px; font-family: 宋体;">- (BOOL)peoplePickerNavigationController:(ABPeoplePickerNavigationController *)peoplePicker shouldContinueAfterSelectingPerson:(ABRecordRef)person<br>{<br>return YES;<br>}</span></p>
<ul>
<li>(BOOL)peoplePickerNavigationController:(ABPeoplePickerNavigationController <em>)peoplePicker shouldContinueAfterSelectingPerson:(ABRecordRef)person property:(ABPropertyID)property identifier:(ABMultiValueIdentifier)identifier<br>{<br>ABMultiValueRef phone = ABRecordCopyValue(person, kABPersonPhoneProperty);<br>long index = ABMultiValueGetIndexForIdentifier(phone,identifier);<br>NSString </em>phoneNO = (__bridge NSString *)ABMultiValueCopyValueAtIndex(phone, index);</li>
</ul>
<p>CFStringRef lastName = ABRecordCopyValue(person, kABPersonLastNameProperty);<br>CFStringRef firstName = ABRecordCopyValue(person, kABPersonFirstNameProperty);</p>
<p>NSString <em>lastname = (__bridge_transfer NSString </em>)(lastName);<br>NSString <em>firstname = (__bridge_transfer NSString </em>)(firstName);</p>
<p>if (phone) {<br>[peoplePicker dismissViewControllerAnimated:YES completion:nil];<br>return NO;<br>}<br>return YES;<br>}<br></p>
<p>iOS8的代理方法换了，改成了下面两个，但是方法内部的取值基本相同</p>
<p><span style="font-size: 13px; font-family: 宋体;">// 点击了通讯录名字就会退出</span></p>
<ul>
<li>(void)peoplePickerNavigationController:(ABPeoplePickerNavigationController *)peoplePicker didSelectPerson:(ABRecordRef)person;</li>
</ul>
<p>// 点击了名字里面的电话或邮箱才会退出</p>
<ul>
<li>(void)peoplePickerNavigationController:(ABPeoplePickerNavigationController *)peoplePicker didSelectPerson:(ABRecordRef)person property:(ABPropertyID)property identifier:(ABMultiValueIdentifier)identifier;<br><br>至于会调用哪一个方法，可以根据实际需要去选择，在弹出界面的方法中predicateForSelectionOfPerson 这个属性传false就是调用下面的。</li>
</ul>
<p><span style="font-size: 13px; font-family: 宋体;">    ABPeoplePickerNavigationController *pickervc = [[ABPeoplePickerNavigationController alloc] init];<br>pickervc.predicateForSelectionOfPerson = [NSPredicate predicateWithValue:false];<br>pickervc.peoplePickerDelegate = self;<br>[target presentViewController:pickervc animated:YES completion:nil];<br></span></p>
<p>iOS9系统下的弹出选择器方法 和 代理方法如下</p>
<p><span style="font-size: 13px; font-family: 宋体;"> // 弹出选择器 </span></p>
<ul>
<li>(void)presentPageOnTarget{<br>CNContactPickerViewController *contactVc = [[CNContactPickerViewController     alloc] init];<br>contactVc.delegate = self;<br>[target presentViewController:contactVc animated:YES completion:nil];<br>}</li>
</ul>
<p>// 代理方法</p>
<ul>
<li>(void)contactPicker:(CNContactPickerViewController <em>)picker didSelectContact:(CNContact </em>)contact<br>{<br>SXPersonInfoEntity <em>personEntity = [SXPersonInfoEntity new];<br>NSString </em>lastname = contact.familyName;<br>NSString *firstname = contact.givenName;<br>NSLog(@”%@ %@”, lastname, firstname);<br>personEntity.lastname = lastname;<br>personEntity.firstname = firstname;</li>
</ul>
<p>NSMutableString *fullname = [[NSString stringWithFormat:@”%@%@”,lastname,firstname] mutableCopy];<br>[fullname replaceOccurrencesOfString:@”(null)” withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, fullname.length)];<br>personEntity.fullname = fullname;</p>
<p>NSString <em>fullPhoneStr = [NSString string];<br>NSArray </em>phoneNums = contact.phoneNumbers;<br>for (CNLabeledValue <em>labeledValue in phoneNums) {<br>NSString </em>phoneLabel = labeledValue.label;<br>CNPhoneNumber <em>phoneNumer = labeledValue.value;<br>NSString </em>phoneValue = phoneNumer.stringValue;<br>NSLog(@”%@ %@”, phoneLabel, phoneValue);<br>if (phoneValue.length &gt; 0) {<br>fullPhoneStr = [fullPhoneStr stringByAppendingString:phoneValue];<br>fullPhoneStr = [fullPhoneStr stringByAppendingString:@”,”];<br>}<br>}<br>if (fullPhoneStr.length &gt; 1) {<br>personEntity.phoneNumber = [fullPhoneStr substringToIndex:fullPhoneStr.length - 1];<br>}<br>self.chooseAction(personEntity);<br>}<br><br>这个是点击了名字就直接回调的方法，如果希望点击了属性再回调，则需要加上这一行</p>
<p><span style="font-size: 13px; font-family: 宋体;">contactVc.predicateForSelectionOfContact = [NSPredicate predicateWithValue:false];</span></p>
<p>// 代理方法调用</p>
<ul>
<li>(void)contactPicker:(CNContactPickerViewController <em>)picker didSelectContactProperty:(CNContactProperty </em>)contactProperty<br></li>
</ul>
<p>三、获取全部通讯录信息<br>关于批量获取所有通讯录信息的方法有点冗长，这里就不一一贴了，只贴下iOS9的写法，iOS7和8的代码demo里都有。</p>
<p><span style="font-size: 13px; font-family: 宋体;">- (void)printAllPerson<br>{<br>// 获取<br>CNContactStore <em>contactStore = [[CNContactStore alloc] init];<br>NSArray </em>keys = @[CNContactGivenNameKey, CNContactFamilyNameKey, CNContactPhoneNumbersKey];<br>CNContactFetchRequest *request = [[CNContactFetchRequest alloc] initWithKeysToFetch:keys];</span></p>
<p>// 遍历<br>[contactStore enumerateContactsWithFetchRequest:request error:nil usingBlock:^(CNContact <em> _Nonnull contact, BOOL </em> _Nonnull stop) {<br>NSString <em>lastname = contact.familyName;<br>NSString </em>firstname = contact.givenName;<br>NSLog(@”%@ %@”, lastname, firstname);<br>NSArray <em>phoneNums = contact.phoneNumbers;<br>for (CNLabeledValue </em>labeledValue in phoneNums) {<br>NSString <em>phoneLabel = labeledValue.label;<br>CNPhoneNumber </em>phoneNumer = labeledValue.value;<br>NSString *phoneValue = phoneNumer.stringValue;<br>NSLog(@”%@ %@”, phoneLabel, phoneValue);<br>}<br>}];<br>}<br></p>
<p>四、写入通讯录<br>因为写入的话这个功能有点重量级，写入的时候要写入，名字、电话、email、地址等等，这就会使得api过于复杂。暂时我见到过的做法大多都是如果用户给了通讯录权限 那就给你插入一条名字+电话，我做了只有这两个入参的api，当然使用时也完全可以扩展成更多参数的。</p>
<p>iOS7和8</p>
<p><span style="font-size: 13px; font-family: 宋体;">- (void)creatItemWithName:(NSString <em>)name phone:(NSString </em>)phone<br>{<br>if((name.length &lt; 1)||(phone.length &lt; 1)){<br>NSLog(@”输入属性不能为空”);<br>return;<br>}<br>CFErrorRef error = NULL;</span></p>
<p>ABAddressBookRef addressBook = ABAddressBookCreateWithOptions(NULL, &amp;error);<br>ABRecordRef newRecord = ABPersonCreate();<br>ABRecordSetValue(newRecord, kABPersonFirstNameProperty, (__bridge CFTypeRef)name, &amp;error);</p>
<p>ABMutableMultiValueRef multi = ABMultiValueCreateMutable(kABMultiStringPropertyType);<br>ABMultiValueAddValueAndLabel(multi, (__bridge CFTypeRef)name, kABPersonPhoneMobileLabel, NULL);</p>
<p>ABRecordSetValue(newRecord, kABPersonPhoneProperty, multi, &amp;error);<br>CFRelease(multi);</p>
<p>ABAddressBookAddRecord(addressBook, newRecord, &amp;error);</p>
<p>ABAddressBookSave(addressBook, &amp;error);<br>CFRelease(newRecord);<br>CFRelease(addressBook);<br>}<br><br>iOS9下</p>
<p><span style="font-size: 13px; font-family: 宋体;">- (void)creatItemWithName:(NSString <em>)name phone:(NSString </em>)phone<br>{<br>// 创建对象<br>// 这个里面可以添加多个电话，email，地址等等。 感觉使用率不高，只提供了最常用的属性：姓名+电话，需要时可以自行扩展。<br>CNMutableContact <em> contact = [[CNMutableContact alloc]init];<br>contact.givenName = name?:@”defaultname”;<br>CNLabeledValue </em>phoneNumber = [CNLabeledValue labeledValueWithLabel:CNLabelPhoneNumberMobile value:[CNPhoneNumber phoneNumberWithStringValue:phone?:@”10086”]];<br>contact.phoneNumbers = @[phoneNumber];</span></p>
<p>// 把对象加到请求中<br>CNSaveRequest * saveRequest = [[CNSaveRequest alloc]init];<br>[saveRequest addContact:contact toContainerWithIdentifier:nil];</p>
<p>// 执行请求<br>CNContactStore * store = [[CNContactStore alloc]init];<br>[store executeSaveRequest:saveRequest error:nil];<br>}<br></p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/11/23/iOS-通讯录写法/" data-id="cipjh2n83000ddhs6iv3noswm" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS-关于蒲公英" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/03/07/iOS-关于蒲公英/" class="article-date">
  <time datetime="2015-03-07T07:50:33.000Z" itemprop="datePublished">2015-03-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/03/07/iOS-关于蒲公英/">iOS_关于蒲公英</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>蒲公英托管平台网站<a href="http://www.pgyer.com/" target="_blank" rel="external">http://www.pgyer.com/</a></p>
<p>首先说一下蒲公英是干什么的，蒲公英就是你程序希望给别的用户测试，但是他手机又没有在的开发者账号列表下，那么就需要企业账号打包才可以给用户进行安装，但是安装你又需要架设一个网页，等等其他麻烦事情，所以使用蒲公英可以简单做到这些事情，你无须有企业账号，只需要能打包成ipa文件即可，然后上传到蒲公英平台上，之后蒲公英就给你一个连接你发送给客户，或者做成二维码扫描即可</p>
<p>原理​</p>
<p>那么你奇怪为什么我随便打个包给他，别人就能下载了，从原理上分析，蒲公英提供了大量的企业级开发者账号，也就是299美金那种，然后你上传ipa文件，他服务器自动把ipa文件拆包，更换里面的签名文件，替换为企业级开发者账号的签名文件，之后在把这个ipa文件的地址发送给你，你下载就是299美金授权那种，这也就解释了​有的时候你在蒲公英上面一段时间后就不行的原因，因为被人举报了，蒲公英要启动一个新的账号，所以那个授权就过期了</p>
<p>注：最新版本的蒲公英需要用户自己提供299美金账号打包了，他不在提供修改ipa文件帮你修改了，这点需要注意​</p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/03/07/iOS-关于蒲公英/" data-id="cipjh2n80000bdhs63h9ppgwv" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS-关于判断VPN小结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/02/17/iOS-关于判断VPN小结/" class="article-date">
  <time datetime="2015-02-17T07:44:09.000Z" itemprop="datePublished">2015-02-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/02/17/iOS-关于判断VPN小结/">iOS_关于判断VPN小结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>需要判断是否开启了VPN方法的代码</p>
<p>头文件需要添加</p>
<p>#include</p>
<p>#include</p>
<p>代码部分</p>
<ul>
<li>(BOOL)isVPNConnected<br>{<br>struct ifaddrs <em>interfaces = NULL;<br>struct ifaddrs </em>temp_addr = NULL;<br>int success = 0;</li>
</ul>
<p>// retrieve the current interfaces - returns 0 on success<br>success = getifaddrs(&amp;interfaces);<br>if (success == 0) {<br>// Loop through linked list of interfaces<br>temp_addr = interfaces;<br>while (temp_addr != NULL) {<br>NSString *string = [NSString stringWithFormat:@”%s” , temp_addr-&gt;ifa_name];<br>if ([string rangeOfString:@”tap”].location != NSNotFound ||<br>[string rangeOfString:@”tun”].location != NSNotFound ||<br>[string rangeOfString:@”ppp”].location != NSNotFound){<br>return YES;<br>}</p>
<p>temp_addr = temp_addr-&gt;ifa_next;<br>}<br>}</p>
<p>// Free memory<br>freeifaddrs(interfaces);<br>return NO;</p>
<p>}</p>
<p>直接调用即可<br>BOOL isSucceess =[self isVPNConnected];</p>
<p>YES为开启了VPN，NO为关闭了VPN</p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/02/17/iOS-关于判断VPN小结/" data-id="cipjh2n85000edhs66hnuondh" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS-JSON解析四种方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/01/07/iOS-JSON解析四种方法/" class="article-date">
  <time datetime="2015-01-07T14:00:23.000Z" itemprop="datePublished">2015-01-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/01/07/iOS-JSON解析四种方法/">iOS_JSON解析四种方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>相关链接：<a href="http://blog.csdn.net/enuola/article/details/7903632" target="_blank" rel="external">http://blog.csdn.net/enuola/article/details/7903632</a></p>
<p>从IOS5开始，APPLE提供了对json的原生支持（NSJSONSerialization），但是为了兼容以前的iOS版本，可以使用第三方库来解析Json。</p>
<p>本文将介绍TouchJson、 SBJson 、JSONKit 和 iOS5所支持的原生的json方法，解析国家气象局API，TouchJson和SBJson需要下载他们的库</p>
<p>TouchJson包下载： <a href="http://download.csdn.net/detail/enuola/4523169" target="_blank" rel="external">http://download.csdn.net/detail/enuola/4523169</a></p>
<p>SBJson 包下载： <a href="http://download.csdn.net/detail/enuola/4523177" target="_blank" rel="external">http://download.csdn.net/detail/enuola/4523177</a></p>
<p>JSONKit包下载：<a href="http://download.csdn.net/detail/enuola/4523160" target="_blank" rel="external">http://download.csdn.net/detail/enuola/4523160</a></p>
<p>下面的完整程序源码包下载：<a href="http://download.csdn.net/detail/enuola/4523223" target="_blank" rel="external">http://download.csdn.net/detail/enuola/4523223</a></p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/01/07/iOS-JSON解析四种方法/" data-id="cipjh2n7t0009dhs64o3jnd4r" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS-三种途径实现一方法有多个返回值" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/03/24/iOS-三种途径实现一方法有多个返回值/" class="article-date">
  <time datetime="2014-03-24T08:24:39.000Z" itemprop="datePublished">2014-03-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/03/24/iOS-三种途径实现一方法有多个返回值/">iOS_三种途径实现一方法有多个返回值</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>以前觉得这种标题有点偏向于理论，实际开发中怎么会有这种诡异的需求，但是真正遇到了这种硬需求时觉得还是有那么点价值的，理论付诸了实践在此也就做了个整理。</p>
<p>以我私下开发中的一处代码为例，本意是希望有这么一个方法：能够传入一个开始标记（NSString<em>）一个结束标记（NSString</em>）一段文字（NSString*）  然后内部在文字中扫描并返回标记包裹内容的范围（NSRange这个范围是忽视标记的）这个范围可能会有多个所以返回的应该是一个装着range的数组。并且顺便把原来字符串中的开始和结束标记全过滤掉，把过滤后的字符串也返回出来。</p>
<p>举个例子就是：传入开始标记“&lt;” 结束标记“&gt;” 一段文字 “会议需要叫上&lt;彼得&gt;和&lt;罗宾&gt;”   然后希望返回一个数组 [{location:6,length:2},{location:9,length:2}] ，和返回处理后的字符串“会议需要叫上彼得和罗宾”。</p>
<p>代码希望能够写成这样，但是是不可能的。</p>
<p>1</p>
<ul>
<li>(NSArray <em>,NSMutableString </em>)scanBeginStr:(NSString <em>)beginstr endStr:(NSString </em>)endstr inText:(NSMutableString *)text</li>
</ul>
<p>好下面提供三种途径完成此需求。　　</p>
<p>1.使用字典</p>
<p>这种方法是最low但是最容易理解的，就是如果你需要返回多个对象，直接将多个对象塞在一个字典里面自己设置合理的key并返回字典，字典里面可以放任意数量的“返回值”。</p>
<ul>
<li>(NSDictionary <em>)scanBeginStr:(NSString </em>)beginstr endStr:(NSString <em>)endstr inText:(NSMutableString </em>)text{<br>NSRange range1,range2;<br>NSUInteger location =0,length=0;<br>range1.location = 0;<br>NSMutableArray *rangeArray = [NSMutableArray array];<br>while (range1.location != NSNotFound) {<br>range1 = [text rangeOfString:beginstr];<br>range2 = [text rangeOfString:endstr];<br>if (range1.location != NSNotFound) {<br>location = range1.location;<br>length = range2.location - range1.location - 1;<br>if (length &gt; 5000)break;<br>[text replaceOccurrencesOfString:beginstr withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, range1.location + range1.length)];<br>[text replaceOccurrencesOfString:endstr withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, range2.location + range2.length - 1)];<br>}<br>[rangeArray addObject:@{@”location”:@(location),@”length”:@(length)}];<br>}<br>return @{@”rangeArray”:rangeArray,@”text”:text};<br>}<br>这个方法在调用时也就是这样了，非常朴实的代码。</li>
</ul>
<p>NSDictionary<em> result = [self scanBegin2Str:@”&lt;” endStr:@”&gt;” inText:mutableText];<br>NSArray </em>rangeArray = result[@”rangeArray”];<br>NSMutableString *text = [result[@”text”] mutableCopy];<br>如果觉得字典不舒服也完全可以用模型，自定义一个对象然后给这个对象的各个属性赋值然后再把这个自定义对象返回回去，虽然代码看上去更科学一点但是需要写一些额外的代码并且不能实现任意可配置（每一种属性都必须要提前设定好），这个和上面算是一个相同的思路就不单独再列一条说了。 </p>
<p>2.使用指针的指针</p>
<p>这种方法是我实际使用的方法，就是把需要修改的text的指针的指针传进去，然后在方法的内部对这个实参取一下值得到text的指针。然后通过这个指针修改外部的变量的值。代码实现如下</p>
<ul>
<li>(NSArray <em>)scanBeginStr:(NSString </em>)beginstr endStr:(NSString <em>)endstr inText:(NSMutableString </em> <em>)textPointer{<br>NSRange range1,range2;<br>NSUInteger location =0,length=0;<br>range1.location = 0;<br>NSMutableString </em>text = <em>textPointer;<br>NSMutableArray </em>rangeArray = [NSMutableArray array];<br>while (range1.location != NSNotFound) {<br>range1 = [text rangeOfString:beginstr];<br>range2 = [text rangeOfString:endstr];<br>if (range1.location != NSNotFound) {<br>location = range1.location;<br>length = range2.location - range1.location - 1;<br>if (length &gt; 5000)break;<br>[text replaceOccurrencesOfString:beginstr withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, range1.location + range1.length)];<br>[text replaceOccurrencesOfString:endstr withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, range2.location + range2.length - 1)];<br>}<br>[rangeArray addObject:@{@”location”:@(location),@”length”:@(length)}];<br>}<br>return rangeArray;<br>}<br>这个方法在调用时就这么写了，因为mutabletext的修改是无声无息的。</li>
</ul>
<p>NSArray *rangeArray = [self scanBegin3Str:@”&lt;” endStr:@”&gt;” inText:&amp;mutableText];<br>// 董铂然博客园
　　</p>
<p>3.使用block回调</p>
<p>这种方法实际上严格意义来说不能算返回值，但是能够实现返回值的效果。</p>
<ul>
<li>(void)scanBeginStr:(NSString <em>)beginstr endStr:(NSString </em>)endstr inText:(NSMutableString <em>)text result:(void(^)(NSArray </em>rangeArray,NSMutableString <em>text))result{<br>NSRange range1,range2;<br>NSUInteger location =0,length=0;<br>range1.location = 0;<br>NSMutableArray </em>rangeArray = [NSMutableArray array];<br>while (range1.location != NSNotFound) {<br>range1 = [text rangeOfString:beginstr];<br>range2 = [text rangeOfString:endstr];<br>if (range1.location != NSNotFound) {<br>location = range1.location;<br>length = range2.location - range1.location - 1;<br>if (length &gt; 5000)break;<br>[text replaceOccurrencesOfString:beginstr withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, range1.location + range1.length)];<br>[text replaceOccurrencesOfString:endstr withString:@”” options:NSCaseInsensitiveSearch range:NSMakeRange(0, range2.location + range2.length - 1)];<br>}<br>[rangeArray addObject:@{@”location”:@(location),@”length”:@(length)}];<br>}<br>result(rangeArray,text);<br>}<br>这个block在使用时可能比较特殊就这么写了</li>
</ul>
<p>[self scanBeginStr:@”&lt;” endStr:@”&gt;” inText:mutabletext result:^(NSArray <em>rangeArray, NSMutableString </em>text) {<br>NSLog(@”%@,%@”,rangeArray,text);<br>}];<br>如果把block的返回值写成一个字典或是模型也可以，但是那就多此一举了。 返回值不能尝试结构体类型，结构体内不能用OC对象只能用基本数据类型。</p>
<p>其实感觉还有别的方法，比如设置N个成员变量在方法内部计算后重新set也完全可以，但是可能大家也知道成员变量多了比较恶心。最近比较火的函数式编程一直在倡导“方法内不能产生副作用”“实现引用透明” ，如果这么看那后两种方法就不符合FP的规则了，但是用着也有自己的特色。</p>
<p>原文链接：<a href="http://www.cnblogs.com/dsxniubility/p/5122146.html" target="_blank" rel="external">http://www.cnblogs.com/dsxniubility/p/5122146.html</a></p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2014/03/24/iOS-三种途径实现一方法有多个返回值/" data-id="cipjh2n7o0008dhs6fip7lda1" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-iOS-APP上线性能检测" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/02/20/iOS-APP上线性能检测/" class="article-date">
  <time datetime="2014-02-20T08:16:38.000Z" itemprop="datePublished">2014-02-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/02/20/iOS-APP上线性能检测/">iOS_APP上线性能检测</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><span></span></p>
<p>相关链接：<a href="http://www.cnblogs.com/dsxniubility/p/5493117.html" target="_blank" rel="external">http://www.cnblogs.com/dsxniubility/p/5493117.html</a></p>
<p>在移动端开发者中最重要的KPI应该是崩溃率。当崩溃率稳定下来后，工作的重心就应该转移到性能优化上。那么问题来了，如果你的项目也没有接入任何性能监测SDK，没有量化的指标来衡量，那你说你优化了性能领导信么？</p>
<p>虽然现在市面上第三方性能检测平台已经很成熟，但笔者还是比较建议公司自己写自己的sdk，原因如下</p>
<ol>
<li><p>数据安全</p>
</li>
<li><p>避开费用，有的平台是MAU三万以下不收费，超出后费用极高。</p>
</li>
<li><p>可以自定义指标没有无用代码，一接别人SDK包体积增大不少，其实你只用到了个别几个功能。</p>
</li>
</ol>
<p>本文主要内容是给小项目团队自己写性能sdk的建议，也会提到当前的第三方平台。</p>
<p>1.页面的打开速度</p>
<p>关于页面的加载速度的测量有两个指标，一个是页面渲染速度，一个是页面加载速度。</p>
<p>页面渲染速度就是计算一个viewcontroller从viewdidload的第一行到viewdidappear的最后一行所用的时间。 这种方法可以适用于大多数相对静态的页面，一打开就直接加载的。  </p>
<p>页面加载速度相对比较麻烦，适用于有些页面并不是一进入就加载而是先发个请求，请求回调后才继续搭建页面的。加载时间应该是用户点开页面到用户能完全的看到内容才算加载完毕，这里就需要算进去请求消耗的时间了，对于源码级别的sdk，我们可以通过每发出一个请求就记到栈里，回调一个消除一个，当栈里的每一个请求都已经回调后才能认定是界面加载完毕。 业界也有一些黑盒的云测平台是录屏解析视频流，认定一个页面从打开到页面稳定后为加载时间。 个人认为肯定没有源码级别的准啊。 （董铂然博客园）</p>
<p>关于这种接入一个sdk直接hook每个页面生命周期方法也简单提一下吧，就是写一个类作为UIViewController的分类，增加几个方法如XXXviewdidload ， XXXviewdidappear等，然后使用这种swizzle的做法替换方法的实现</p>
<p><span style="font-family: 宋体; font-size: 13px;">    Method viewDidAppear = class_getInstanceMethod([UIViewController class], @selector(viewDidAppear:));<br>Method XXXViewDidAppear = class_getInstanceMethod([UIViewController class], @selector(XXXViewDidAppear:));<br>method_exchangeImplementations(viewDidAppear, XXXViewDidAppear);<br></span><br>对于一些新增的计量属性就使用运行时关联对象的那一套吧。 如果觉得要hook的方法太多或是太麻烦或是怕和别的hook冲突，可以使用埋点的方式，直接埋上你需要计算的开始和结束时间的采集点，这种更加灵活只关心自己关心的页面。</p>
<p>2.内存使用值</p>
<p>关于内存和cpu的获取方法业内基本都有统一的代码了，大致如下。</p>
<p><span style="font-family: 宋体; font-size: 13px;">+ (unsigned long)memoryUsage<br>{<br>struct task_basic_info info;<br>mach_msg_type_number_t size = sizeof(info);<br>kern_return_t kr = task_info(mach_task_self(), TASK_BASIC_INFO, (task_info_t)&amp;info, &amp;size);<br>if (kr != KERN_SUCCESS) {<br>return -1;<br>}<br>unsigned long memorySize = info.resident_size &gt;&gt; 10;</span></p>
<p>return memorySize;<br>}<br>需要先引入这两个头文件</p>
<p>1<br>2<br><span style="font-family: 宋体; font-size: 13px;">#include <mach task_info.h=""></mach></span></p>
<p>#include <mach mach.h=""><br>获取到了数据存入数组那接下来的事情就是上报策略的制定了。没必要每次获取数据都上报，可以设置每次启动上报上一次session的全部记录就好，启动后隔个10秒或20秒错开请求高峰期。上报时的数据结构也要尽可能的精简，因为不能对用户的流量造成太大的损失，也可以选择先压缩后再上传。 </mach></p>
<p>3.CPU占用率</p>
<p>同样需要内存的那两个头文件</p>
<p><span style="font-family: 宋体; font-size: 13px;">+ (CGFloat)cpuUsage<br>{<br>thread_array_t         thread_list;<br>mach_msg_type_number_t thread_count;<br>thread_info_data_t     thinfo;<br>mach_msg_type_number_t thread_info_count;<br>thread_basic_info_t basic_info_th;</span></p>
<p>// get threads in the task<br>kern_return_t kr = task_threads(mach_task_self(), &amp;thread_list, &amp;thread_count);<br>if (kr != KERN_SUCCESS) {<br>return -1;<br>}</p>
<p>CGFloat tot_cpu = 0;</p>
<p>for (int j = 0; j &lt; thread_count; j++)</p>
<p>{<br>thread_info_count = THREAD_INFO_MAX;<br>kr = thread_info(thread_list[j], THREAD_BASIC_INFO,(thread_info_t)thinfo, &amp;thread_info_count);<br>if (kr != KERN_SUCCESS) {<br>return -1;<br>}</p>
<p>basic_info_th = (thread_basic_info_t)thinfo;</p>
<p>if (!(basic_info_th-&gt;flags &amp; TH_FLAGS_IDLE)) {<br>tot_cpu = tot_cpu + basic_info_th-&gt;cpu_usage / (CGFloat)TH_USAGE_SCALE * 100.0;<br>}</p>
<p>} // for each thread<br>//free mem<br>kr = vm_deallocate(mach_task_self(), (vm_offset_t)thread_list, thread_count * sizeof(thread_t));<br>assert(kr == KERN_SUCCESS);<br>return tot_cpu;<br>}<br>关于采集数据的频率完全是自己制定的，而且大部分app都是在刚启动不久内cpu占用较大 之后就渐渐区域稳定，所以建议在刚开始采集间隔短一点比如1s，之后采集间隔逐渐加大最后稳定到5分钟获取一次。</p>
<p>4.页面的帧率</p>
<p><span style="font-family: 宋体; font-size: 13px;">_link = [CADisplayLink displayLinkWithTarget:self selector:@selector(tick:)];<br>[_link addToRunLoop:[NSRunLoop mainRunLoop] forMode:NSRunLoopCommonModes];</span></p>
<ul>
<li>(void)tick:(CADisplayLink *)link {<br>if (_lastTime == 0) {<br>_lastTime = link.timestamp;<br>return;<br>}<br>_count++;<br>NSTimeInterval delta = link.timestamp - _lastTime;<br>if (delta &lt; 1) return;<br>_lastTime = link.timestamp;<br>float fps = _count / delta;<br>_count = 0;<br>}　　<br>这个测量页面帧率的做法就是通过这个CADisplayLink刷帧方法的调用次数计算的，一般这个方法最快能每秒调用60次，如果是CPU或是GPU某个步骤耗时导致渲染错过了一次垂直信号，那这个方法就不会被调用了，之后统计的帧数也就随之降低了。 上面代码中的fps就是求出的这一时刻的帧率可以塞入数组再稍作处理上传。这里需要注意的是 性能监测平台自己对性能的影响，这个统计帧率的方法可能相对来说要耗性能一些，所以需要控制在某些时刻采集一定的样本就及时暂停。  这个数据建议hook每个页面加载时的方法如viewwillappear，或是tableview滑动时的代理方法，因为卡顿大多发生在这两个场景。 对帧率有兴趣的可以做一个悬浮窗测试帧率，我之前写过一个，但是还没有抽离成组件有兴趣的可以交流下。</li>
</ul>
<p>5.url响应时间监控</p>
<p>这里普通的做法就是继承NSURLProtocol 这个类写一个子类，然后在子类中实现NSURLConnectionDelegate 的那五个代理方法。 </p>
<p><span style="font-family: 宋体; font-size: 13px;">- (NSURLRequest <em>)connection:(NSURLConnection </em>)connection willSendRequest:(NSURLRequest <em>)request redirectResponse:(NSURLResponse </em>)response<br>//  这个方法里可以做计时的开始</span></p>
<ul>
<li><p>(void)connection:(NSURLConnection <em>)connection didReceiveResponse:(NSURLResponse </em>)response<br>//  这里可以得到返回包的总大小</p>
</li>
<li><p>(void)connection:(NSURLConnection <em>)connection didReceiveData:(NSData </em>)data<br>//  这里将每次的data累加起来，可以做加载进度圆环之类的</p>
</li>
<li><p>(void)connectionDidFinishLoading:(NSURLConnection *)connection<br>//  这里作为结束的时间</p>
</li>
<li><p>(void)connection:(NSURLConnection <em>)connection didFailWithError:(NSError </em>)error<br>//  错误的收集 <br>（经过调研connection在升级ipv6后还是可以使用的）你可以得到请求的url，建议只记录host和path，因为吧拼上的参数也上传第一不好快速分类，第二服务端还要做截取处理增加压力，第三浪费流量。 也可以得到response包的length。 响应时间可以根据结束方法中的时间减去开始方法中的时间得到，然后以key-value的方式上传。个人觉得请求没必要与viewcontroller关联，要考虑到管理页面栈还要考虑present和dismiss，收效甚微。并且想知道哪个url属于哪个页面还有很多可执行的方案。</p>
</li>
</ul>
<p>关于webView的url响应时间监控，比普通的native内url要复杂一些。 虽然上面说的统计方法也可以统计到webview的url响应时间，但是只能统计到完整url时间。webView的打开时可能会伴随一些302跳转之类的url，最后才到目标url。 如果一个url经历了三次跳转，响应时间很长，用上面说的统计方法只能统计总时间并不能定位到具体是哪一个子url异常。 这时就需要webView内特殊的时间统计了。</p>
<p>有的一个url会调多个不同团队维护的服务导致了重定向（图中ABC都是完整url的子url），分别在webView的两个代理方法中埋点计算差值，从A走了didstart到B走了didstart这个时间的差值为①就是A所消耗的时间，①+②+③是完整的时间。 通过这种分离统计的方法，可以把慢url明确定位到每一个服务，不对拖累好人。</p>
<p>6.请求错误码统计</p>
<p>如果没有做错误码统计的话，你服务器有问题或者某些地区被运营商劫持之类的，你app的界面可能显示的就是一直转菊花，这时是无法精确定位问题的。 所以将自己的请求都进行编号并收集错误码是非常有必要的。 我们所关注的错误码有三种：</p>
<ol>
<li><p>正常的HTTP Response code 比如200 ，404，500   </p>
</li>
<li><p>AFN（现在ASI用不了了，ipv6强制升级后 应该大部分人都是用AFN3.0了）指定的code 如 -1101, 1102等</p>
</li>
<li><p>你自己请求制定的errorcode。 如 errorcode : 7, message : “您还没有登录” 或 errorcode:10,message:”签名验证失败” </p>
</li>
</ol>
<p>还有很重要一点，就是将自己的所有接口做成一整套映射的编号， 举个例子67对应的是persondetail接口。出现了请求错误，上传的请求错误码应该包含两个部分：接口编号+错误编号。 错误编号建议优先使用自己制定的errcode，其次是AFNcode，最后才是HTTPresponsecode。</p>
<p>“67-10” “35-404” 如果以后上报了类似的错误码，当然比只看到转菊花要好定位的多。</p>
<p>最后提当下的第三方性能监控平台，有听云，OneApm，博睿。 这里就不一一对比每一个平台的优缺点了，因为大体上都是差不多的。</p>
<p>就拿oneapm来说吧，首先ui做的比其他今个平台都要好，让人感觉更专业一点。  接入的方式也是对代码侵入性较小，接一个SDK大小6M左右，加几个framework，然后main函数加一行代码，上传的token是注册后生成的。</p>
<p>我在自己github的一个库里接了这个sdk，后来发现用的人还不少。里面有demo和一些性能监测平台的截图有兴趣可以去看看</p>
<p><a href="https://github.com/dsxNiubility/SXNews" target="_blank" rel="external">https://github.com/dsxNiubility/SXNews</a>  </p>
<p>核心功能（这里说一下，我只用了这些平台的移动端功能）也就是包括：UI交互，url响应时间，用户的版本地域系统分布，及crash。 其中崩溃率如果需要统计的话需要手动上传dsym文件。  并且用着用着就遇到了我前面说的问题，有一些我们不需要的功能，并且也有一些我们需要他却没有的功能，比如帧率和webView中的子url响应时间。 优点内就是FE展示时指标内的图表很清晰，并且可以自定义定制仪表盘。这是一个小公司自己写sdk前期难以达到的。  还有一点就是可配置，在设置页面可以自行选择自己所关注的指标。 然后程序每次启动都会先有一个GET请求获取配置，哪些打开哪些关闭，然后测量和上传我们需要的（这里有一点可疑的是，他是真没测量还是全都测量上传了，只是在控制台里不给你展示罢了），我们自写的sdk做个可配置也是必要的。</p>
<p></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2014/02/20/iOS-APP上线性能检测/" data-id="cipjh2n7x000adhs6tgeqg37x" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">March 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">February 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">January 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/03/">March 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/02/">February 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/01/">January 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">December 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/11/">November 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/10/">October 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/09/">September 2013</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/02/15/搞定iOS与js交互/">搞定iOS与js交互</a>
          </li>
        
          <li>
            <a href="/2016/01/28/移动直播开发技术介绍/">移动直播开发技术介绍</a>
          </li>
        
          <li>
            <a href="/2016/01/22/Bilibili开源的直播框架/">Bilibili开源的直播框架</a>
          </li>
        
          <li>
            <a href="/2016/01/14/iOS三种视屏录制方式/">iOS三种视屏录制方式</a>
          </li>
        
          <li>
            <a href="/2015/11/23/iOS-通讯录写法/">iOS_通讯录写法</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 John Doe<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>